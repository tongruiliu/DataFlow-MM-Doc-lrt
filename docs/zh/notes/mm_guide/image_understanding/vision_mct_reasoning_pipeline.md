---
title: è§†è§‰ MCTS æ¨ç†é“¾ç”Ÿæˆæµæ°´çº¿
icon: mdi:image-text
createTime: 2026/01/11 21:59:59
permalink: /zh/mm_guide/vision_mct_reasoning_pipeline/
---

## 1. æ¦‚è¿°

**è§†è§‰ MCTS æ¨ç†é“¾ç”Ÿæˆæµæ°´çº¿ (Vision MCTS Reasoning Pipeline)** æ—¨åœ¨ä¸ºå¤šæ¨¡æ€å¤§æ¨¡å‹æ„å»ºé«˜è´¨é‡çš„**è¿‡ç¨‹ç›‘ç£æ•°æ®ï¼ˆProcess Supervision Dataï¼‰**ã€‚è¯¥æµæ°´çº¿èƒ½å¤Ÿå¤„ç†ä¸¤ç§æ•°æ®æ¥æºï¼šå·²æœ‰çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰è½¨è¿¹æ•°æ®ï¼Œæˆ–ç›´æ¥åˆ©ç”¨ VLM ç”Ÿæˆæ–°çš„æ¨ç†é“¾ã€‚

è¯¥æµæ°´çº¿æ˜¯ **Grounded-RL** å’Œ **SFT æ•°æ®æ„å»º**çš„æ ¸å¿ƒå·¥å…·ï¼Œå®ƒå°†å¤æ‚çš„æ ‘çŠ¶æœç´¢è¿‡ç¨‹â€œçº¿æ€§åŒ–â€ä¸ºæ¨¡å‹å¯å­¦ä¹ çš„ `<think>...</think><answer>...</answer>` æ ¼å¼ã€‚

æˆ‘ä»¬æ”¯æŒä»¥ä¸‹åº”ç”¨åœºæ™¯ï¼š

* **ä» MCTS æ ‘æå–æ•°æ®**ï¼šå°†æœç´¢æ ‘ä¸­é«˜ä»·å€¼çš„è·¯å¾„ï¼ˆRolloutsï¼‰è½¬åŒ–ä¸ºçº¿æ€§è®­ç»ƒæ•°æ®ã€‚
* **æ··åˆæ•°æ®æ„å»º**ï¼šå¯¹äºæ²¡æœ‰æœç´¢æ ‘çš„æ ·æœ¬ï¼Œè‡ªåŠ¨å›é€€åˆ°ä½¿ç”¨ VLM è¿›è¡Œ CoT ç”Ÿæˆã€‚
* **ç©ºé—´æ¨ç†å¢å¼º**ï¼šæ”¯æŒç”ŸæˆåŒ…å«æ˜¾å¼åæ ‡ï¼ˆBounding Boxï¼‰çš„ç©ºé—´æ¨ç†é“¾ã€‚

æµæ°´çº¿çš„ä¸»è¦æµç¨‹åŒ…æ‹¬ï¼š

1. **MCTS æ ‘è§£æ**ï¼šè§£æè¾“å…¥æ•°æ®ä¸­çš„æœç´¢æ ‘ç»“æ„ï¼Œæå–æˆåŠŸçš„æ¨ç†è·¯å¾„ã€‚
2. **è§†è§‰æ¨ç†ç”Ÿæˆ (Fallback)**ï¼šå¯¹äºç¼ºå¤±æ ‘ç»“æ„æˆ–è§£æå¤±è´¥çš„æ ·æœ¬ï¼Œåˆ©ç”¨ VLM é‡æ–°ç”Ÿæˆæ¨ç†é“¾ã€‚
3. **æ•°æ®æ ‡å‡†åŒ–**ï¼šè¾“å‡ºç»Ÿä¸€æ ¼å¼çš„æ¨ç†é“¾æ•°æ®ã€‚

---

## 2. å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡å·¥ä½œç›®å½•

```bash
mkdir run_mcts_reasoning
cd run_mcts_reasoning

```

### ç¬¬äºŒæ­¥ï¼šåˆå§‹åŒ– DataFlow-MM

```bash
dataflowmm init

```

è¿™æ—¶ä½ ä¼šçœ‹åˆ°ï¼š

```bash
gpu_pipelines/vision_mct_reasoning_pipeline.py

```

### ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½ç¤ºä¾‹æ•°æ®

```bash
huggingface-cli download --repo-type dataset OpenDCAI/dataflow-demo-image --local-dir ./example_data

```

### ç¬¬å››æ­¥ï¼šé…ç½®å‚æ•°

ç¡®ä¿è¾“å…¥æ–‡ä»¶ï¼ˆjsonlï¼‰åŒ…å« `tree` å­—æ®µï¼ˆç”¨äºæå–ï¼‰æˆ–ä»…åŒ…å« `question/image`ï¼ˆç”¨äºç”Ÿæˆï¼‰ï¼š

```python
if __name__ == "__main__":
    pipe = VisionMCTSReasoningPipeline(
        model_path="Qwen/Qwen2.5-VL-3B-Instruct",
        first_entry_file="../example_data/capsbench_images/visual_mct_reasoning_demo.jsonl",
        prompt_type="spatial",
        hf_cache_dir="~/.cache/huggingface",
        download_dir="../ckpt/models/Qwen2.5-VL-3B-Instruct",
    )
    pipe.forward()

```

> **âš ï¸ æ¨¡å‹è·¯å¾„é…ç½®çš„é‡è¦æç¤ºï¼ˆä»¥ `Qwen2.5-VL-3B-Instruct` ä¸ºä¾‹ï¼‰ï¼š**
> * **å¦‚æœæ‚¨å·²ç»ä¸‹è½½å¥½äº†æ¨¡å‹æ–‡ä»¶**ï¼šè¯·å°† `model_path` ä¿®æ”¹ä¸ºæ‚¨çš„æœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚**åŠ¡å¿…ä¿è¯**æ¨¡å‹å­˜æ”¾çš„æœ€ç»ˆæ–‡ä»¶å¤¹åç§°ç²¾ç¡®ä¸º `Qwen2.5-VL-3B-Instruct`ï¼Œå¦åˆ™åº•å±‚è§£ææ—¶å°†æ— æ³•æ­£ç¡®åŒ¹é…å’Œè¯†åˆ«è¯¥æ¨¡å‹ã€‚
> * **å¦‚æœæ‚¨è¿˜æœªä¸‹è½½æ¨¡å‹ï¼ˆéœ€è¦è‡ªåŠ¨ä¸‹è½½ï¼‰**ï¼šè¯·ä¸€å®šè¦æŒ‡å®š `download_dir` å‚æ•°ï¼Œå¹¶ä¸”è¯¥ç›®å½•è·¯å¾„**å¿…é¡»ä»¥** `Qwen2.5-VL-3B-Instruct` **ç»“å°¾**ï¼ˆæ­£å¦‚é»˜è®¤å‚æ•°æ‰€ç¤ºï¼‰ï¼Œå¦åˆ™ä¸‹è½½å®ŒæˆååŒæ ·ä¼šå¯¼è‡´æ¡†æ¶æ— æ³•è¯†åˆ«æ¨¡å‹ã€‚
> 
> 

### ç¬¬äº”æ­¥ï¼šä¸€é”®è¿è¡Œ

```bash
cd gpu_pipelines
python vision_mct_reasoning_pipeline.py

```

> **ğŸ› ï¸ å¸¸è§é—®é¢˜æ’æŸ¥ (Troubleshooting)**
> **é—®é¢˜ 1ï¼š** å¦‚æœé‡åˆ°ç±»ä¼¼å¦‚ä¸‹çš„åŠ¨æ€é“¾æ¥åº“å†²çªæŠ¥é”™ï¼š
> `ImportError: .../miniconda3/envs/Dataflow-MM/lib/python3.12/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkComplete_12_4, version libnvJitLink.so.12`
> **è§£å†³æ–¹æ³•ï¼š** è¿™é€šå¸¸æ˜¯ç¯å¢ƒå˜é‡å¹²æ‰°å¯¼è‡´çš„ã€‚è¯·åœ¨è¿è¡Œå‘½ä»¤å‰æ¸…ç©º `LD_LIBRARY_PATH`ï¼š
> ```bash
> LD_LIBRARY_PATH="" python vision_mcts_pipeline.py
> 
> ```
> 
> 
> **é—®é¢˜ 2ï¼š** å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ **Qwen ç³»åˆ—æ¨¡å‹**ï¼Œå¹¶ä¸”é‡åˆ°ä»¥ä¸‹æŠ¥é”™ï¼š
> `KeyError: "Missing required keys in rope_scaling for 'rope_type'='None': {'rope_type'}"`
> **è§£å†³æ–¹æ³•ï¼š** æ‰“å¼€æ¨¡å‹æ–‡ä»¶å¤¹ä¸‹çš„ `config.json` æ–‡ä»¶ï¼Œæ‰¾åˆ° `rope_scaling` é…ç½®å—ï¼Œå°† `"type"` å­—æ®µä¿®æ”¹ä¸º `"rope_type"` å³å¯ã€‚
> **ä¿®æ”¹å‰ï¼š**
> ```json
> "rope_scaling": {
>   "type": "mrope",
>   "mrope_section": [
>     16,
>     24,
>     24
>   ]
> }
> 
> ```
> 
> 
> **ä¿®æ”¹åï¼š**
> ```json
> "rope_scaling": {
>   "rope_type": "mrope",
>   "mrope_section": [
>     16,
>     24,
>     24
>   ]
> }
> 
> ```
> 
> 

---

## 3. æ•°æ®æµä¸æµæ°´çº¿é€»è¾‘

### 1. **è¾“å…¥æ•°æ®**

è¾“å…¥æ•°æ®é€šå¸¸æ¥æºäº MCTS æœç´¢è¿‡ç¨‹çš„æ—¥å¿—ï¼Œæˆ–æœªæ ‡æ³¨çš„å›¾æ–‡å¯¹ï¼š

* **image**ï¼šå›¾åƒè·¯å¾„ã€‚
* **question**ï¼šè§†è§‰é—®é¢˜ã€‚
* **tree**ï¼ˆå¯é€‰ï¼‰ï¼šMCTS æœç´¢æ ‘çš„ JSON ç»“æ„ï¼ŒåŒ…å«èŠ‚ç‚¹å€¼ï¼ˆValueï¼‰ã€è®¿é—®æ¬¡æ•°ï¼ˆVisitsï¼‰å’ŒåŠ¨ä½œï¼ˆActionsï¼‰ã€‚

**è¾“å…¥æ•°æ®ç¤ºä¾‹**ï¼š

```json
{
    "image": "./images/puzzle.jpg",
    "question": "What is the next step to solve this?",
    "tree": { "root": { "children": [...], "value": 1.0, "text": "Step 1..." } }
}

```

### 2. **æ ¸å¿ƒç®—å­é€»è¾‘**

è¯¥æµæ°´çº¿é‡‡ç”¨ **â€œæå–ä¼˜å…ˆï¼Œç”Ÿæˆå…œåº•â€** çš„æ··åˆç­–ç•¥ï¼š

#### A. **MCTSTreeRefinerï¼ˆæ ‘ç»“æ„è§£æå™¨ï¼‰**

è¯¥ç®—å­è´Ÿè´£å¤„ç† `tree` å­—æ®µã€‚å®ƒéå†æ ‘ç»“æ„ï¼Œæ ¹æ®èŠ‚ç‚¹ä»·å€¼ï¼ˆQ-valueï¼‰ç­›é€‰å‡ºä»æ ¹èŠ‚ç‚¹åˆ°å¶å­èŠ‚ç‚¹çš„æœ€ä½³è·¯å¾„ã€‚

* **è¾“å…¥**ï¼š`tree` å¯¹è±¡ã€‚
* **åŠŸèƒ½**ï¼šçº¿æ€§åŒ–æ ‘è·¯å¾„ï¼Œè¿‡æ»¤æ‰ä½ä»·å€¼æˆ–æœªå®Œæˆçš„æœç´¢åˆ†æ”¯ã€‚
* **è¾“å‡º**ï¼šæå–å‡ºçš„æ¨ç†é“¾åˆ—è¡¨ï¼ˆ`mcts_chains`ï¼‰ã€‚

#### B. **VisualReasoningGeneratorï¼ˆè§†è§‰æ¨ç†ç”Ÿæˆå™¨ï¼‰**

è¯¥ç®—å­æ˜¯æµæ°´çº¿çš„â€œç”Ÿæˆå¼•æ“â€ã€‚å®ƒæ¥æ”¶ä¸Šä¸€æ­¥çš„æå–ç»“æœä½œä¸ºè¾“å…¥ã€‚

* **æœºåˆ¶**ï¼šæ£€æŸ¥ `input_existing_chains_key`ï¼ˆå³ `mcts_chains`ï¼‰ã€‚
* å¦‚æœ MCTS è§£ææˆåŠŸï¼ˆé“¾å­˜åœ¨ï¼‰ï¼Œåˆ™ç›´æ¥å¤ç”¨ï¼Œä¸è¿›è¡Œæ¨ç†ï¼ˆèŠ‚çœè®¡ç®—èµ„æºï¼‰ã€‚
* å¦‚æœ MCTS é“¾ä¸ºç©ºï¼ˆæ ‘ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥ï¼‰ï¼Œåˆ™è°ƒç”¨ VLMï¼Œæ ¹æ® `prompt_type`ï¼ˆå¦‚ `spatial`ï¼‰ä»å¤´ç”Ÿæˆæ¨ç†é“¾ã€‚


* **Prompt ç±»å‹**ï¼šæ”¯æŒ `spatial`ï¼ˆç©ºé—´åæ ‡æ¨ç†ï¼‰ã€`logical`ï¼ˆé€»è¾‘æ¨ç†ï¼‰ç­‰æ¨¡å¼ã€‚

### 3. **è¾“å‡ºæ•°æ®**

æœ€ç»ˆç”Ÿæˆçš„è¾“å‡ºæ•°æ®ï¼ˆ`final_reasoning_chains`ï¼‰å°†åŒ…å«é«˜è´¨é‡çš„æ€ç»´é“¾ï¼Œå¯ç›´æ¥ç”¨äº SFT è®­ç»ƒã€‚

**è¾“å‡ºç¤ºä¾‹**ï¼š

```json
{
    "image": "./images/puzzle.jpg",
    "final_reasoning_chains": [
        "<think>First, locate the red block at [100, 200]. To solve the puzzle, it needs to move right...</think><answer>Move Red Block</answer>"
    ]
}

```

---

## 4. æµæ°´çº¿ç¤ºä¾‹

ä»¥ä¸‹æ˜¯å®Œæ•´çš„ `VisionMCTSReasoningPipeline` ä»£ç å®ç° (GPU ç‰ˆæœ¬)ã€‚

```python
from dataflow.utils.storage import FileStorage
from dataflow.serving.local_model_vlm_serving import LocalModelVLMServing_vllm

# å¼•å…¥åŸå­ç®—å­
from dataflow.operators.core_text import MCTSTreeRefiner
from dataflow.operators.core_vision import VisualReasoningGenerator

class VisionMCTSReasoningPipeline:
    def __init__(
        self,
        model_path: str,
        *,
        # Storage
        hf_cache_dir: str | None = None,
        download_dir: str = "./ckpt/models",
        first_entry_file: str,
        cache_path: str = "../cache/cache_mcts",
        file_name_prefix: str = "mcts_reason",
        # Config
        prompt_type: str = "spatial",
        max_samples_per_file: int = 10000,
        # Keys
        input_question_key: str = "question",
        input_image_key: str = "image",
        input_tree_key: str = "tree",
        output_key: str = "final_reasoning_chains",
        # VLLM
        vllm_max_tokens: int = 1024
    ):
        self.storage = FileStorage(
            first_entry_file_name=first_entry_file,
            cache_path=cache_path,
            file_name_prefix=file_name_prefix,
            cache_type="jsonl"
        )
        
        self.serving = LocalModelVLMServing_vllm(
            hf_cache_dir=hf_cache_dir,
            hf_local_dir=download_dir,
            hf_model_name_or_path=model_path,
            vllm_tensor_parallel_size=1,
            vllm_temperature=0.7,
            vllm_max_tokens=vllm_max_tokens
        )
        
        self.keys = {
            "q": input_question_key,
            "img": input_image_key,
            "tree": input_tree_key,
            "mcts_chains": "mcts_extracted_chains",
            "final": output_key
        }

        # ================== Operators ==================
        
        # 1. Refiner: MCTS -> Chains
        self.op_mcts_refine = MCTSTreeRefiner(
            max_chains_per_sample=max_samples_per_file
        )
        
        # 2. Generator: VLM -> Chains (Fallback)
        self.op_vlm_gen = VisualReasoningGenerator(
            serving=self.serving,
            prompt_type=prompt_type
        )

    def forward(self):
        print(">>> [Pipeline] Step 1: Extracting Chains from MCTS Trees...")
        self.op_mcts_refine.run(
            self.storage.step(),
            input_tree_key=self.keys["tree"],
            output_key=self.keys["mcts_chains"]
        )
        
        print(">>> [Pipeline] Step 2: Generating Chains via VLM (Fallback)...")
        # å°† mcts_chains ä½œä¸º input_existing_chains_key ä¼ å…¥
        # å¦‚æœ MCTS è§£ææˆåŠŸï¼Œåˆ™å¤ç”¨ï¼›å¦åˆ™è°ƒç”¨ VLM ç”Ÿæˆ
        self.op_vlm_gen.run(
            self.storage.step(),
            input_question_key=self.keys["q"],
            input_image_key=self.keys["img"],
            input_existing_chains_key=self.keys["mcts_chains"],
            output_key=self.keys["final"]
        )
        
        
if __name__ == "__main__":
    pipe = VisionMCTSReasoningPipeline(
        model_path="Qwen/Qwen2.5-VL-3B-Instruct",
        first_entry_file="../example_data/capsbench_images/visual_mct_reasoning_demo.jsonl",
        prompt_type="spatial",
        hf_cache_dir="~/.cache/huggingface",
        download_dir="../ckpt/models/Qwen2.5-VL-3B-Instruct",
    )
    pipe.forward()

```
