---
title: å›¾åƒåŒºåŸŸæè¿°ç”Ÿæˆæµæ°´çº¿RegionCap
createTime: 2026/01/11 22:04:27
icon: mdi:image-text
permalink: /zh/mm_guide/image_region_caption_pipeline/
---
## 1. æ¦‚è¿°

**å›¾åƒåŒºåŸŸæè¿°ç”Ÿæˆæµæ°´çº¿ (Image Region Caption Pipeline)** æ—¨åœ¨ä¸ºå›¾åƒä¸­çš„ç‰¹å®šåŒºåŸŸç”Ÿæˆè¯¦ç»†çš„æ–‡æœ¬æè¿°ã€‚è¯¥æµæ°´çº¿ç»“åˆäº†è®¡ç®—æœºè§†è§‰çš„å®šä½èƒ½åŠ›ä¸å¤šæ¨¡æ€å¤§æ¨¡å‹çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¯†åˆ«å›¾åƒä¸­çš„æ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIï¼‰ï¼Œå¹¶ä¸ºå…¶ç”Ÿæˆç²¾ç¡®çš„è‡ªç„¶è¯­è¨€æ ‡æ³¨ã€‚

è¯¥æµæ°´çº¿æ”¯æŒå¤„ç†**é¢„å®šä¹‰è¾¹ç•Œæ¡† (Bounding Box)** æ•°æ®ï¼Œå¹¶å°†å…¶å¯è§†åŒ–åè¾“å…¥ VLM è¿›è¡Œæè¿°ç”Ÿæˆã€‚

æˆ‘ä»¬æ”¯æŒä»¥ä¸‹åº”ç”¨åœºæ™¯ï¼š

* **å¯†é›†æè¿°ç”Ÿæˆ (Dense Captioning)**ï¼šä¸ºå›¾åƒä¸­çš„å¤šä¸ªç‰©ä½“åˆ†åˆ«ç”Ÿæˆæè¿°ã€‚
* **ç»†ç²’åº¦å›¾åƒç†è§£**ï¼šå…³æ³¨å›¾åƒçš„å±€éƒ¨ç»†èŠ‚è€Œéå…¨å±€æè¿°ã€‚
* **æ•°æ®é›†å¢å¼º**ï¼šæ„å»ºå¸¦å®šä½ä¿¡æ¯çš„å›¾æ–‡å¯¹æ•°æ®é›†ã€‚

æµæ°´çº¿çš„ä¸»è¦æµç¨‹åŒ…æ‹¬ï¼š

1. **æ•°æ®åŠ è½½**ï¼šè¯»å–åŒ…å«å›¾åƒå’Œè¾¹ç•Œæ¡†ä¿¡æ¯çš„æºæ•°æ®ã€‚
2. **è¾¹ç•Œæ¡†å¤„ç†ä¸å¯è§†åŒ–**ï¼šå¤„ç†è¾“å…¥çš„è¾¹ç•Œæ¡†ï¼Œç”Ÿæˆå¸¦æœ‰å¯è§†åŒ–æ ‡è®°ï¼ˆå¦‚ç”»æ¡†ï¼‰çš„å›¾åƒç‰ˆæœ¬ã€‚
3. **åŒºåŸŸæè¿°ç”Ÿæˆ**ï¼šåˆ©ç”¨ VLM é’ˆå¯¹æ ‡è®°åçš„å›¾åƒæˆ–ç‰¹å®šåŒºåŸŸç”Ÿæˆæ–‡æœ¬æè¿°ã€‚

---

## 2. å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ–°çš„ DataFlow å·¥ä½œæ–‡ä»¶å¤¹
```bash
mkdir run_dataflow
cd run_dataflow
```

### ç¬¬äºŒæ­¥ï¼šåˆå§‹åŒ– DataFlow-MM
```bash
dataflowmm init
```
è¿™æ—¶ä½ ä¼šçœ‹åˆ°ï¼š
```bash
gpu_pipelines/image_region_caption_pipeline.py
```

### ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½ç¤ºä¾‹æ•°æ®
```bash
huggingface-cli download --repo-type dataset OpenDCAI/dataflow-demo-image --local-dir ./example_data
```

### ç¬¬å››æ­¥ï¼šé…ç½®å‚æ•°
```python
    def __init__(
        self,
        model_path: str = "Qwen/Qwen2.5-VL-3B-Instruct",
        hf_cache_dir: str = "~/.cache/huggingface",
        download_dir: str = "../ckpt/models/Qwen2.5-VL-3B-Instruct",
        first_entry_file: str = "../example_data/image_region_caption/image_region_caption_demo.jsonl",
        cache_path: str = "../cache/image_region_caption",
        file_name_prefix: str = "region_caption",
        cache_type: str = "jsonl",
        input_image_key: str = "image",
        input_bbox_key: str = "bbox",
        max_boxes: int = 10,
        output_image_with_bbox_path: str = "../cache/image_region_caption/image_with_bbox_result.jsonl",
    ):
```
> **âš ï¸ æ¨¡å‹è·¯å¾„é…ç½®çš„é‡è¦æç¤ºï¼ˆä»¥ `Qwen2.5-VL-3B-Instruct` ä¸ºä¾‹ï¼‰ï¼š**
> 
> * **å¦‚æœæ‚¨å·²ç»ä¸‹è½½å¥½äº†æ¨¡å‹æ–‡ä»¶**ï¼šè¯·å°† `model_path` ä¿®æ”¹ä¸ºæ‚¨çš„æœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚**åŠ¡å¿…ä¿è¯**æ¨¡å‹å­˜æ”¾çš„æœ€ç»ˆæ–‡ä»¶å¤¹åç§°ç²¾ç¡®ä¸º `Qwen2.5-VL-3B-Instruct`ï¼Œå¦åˆ™åº•å±‚è§£ææ—¶å°†æ— æ³•æ­£ç¡®åŒ¹é…å’Œè¯†åˆ«è¯¥æ¨¡å‹ã€‚
> * **å¦‚æœæ‚¨è¿˜æœªä¸‹è½½æ¨¡å‹ï¼ˆéœ€è¦è‡ªåŠ¨ä¸‹è½½ï¼‰**ï¼šè¯·ä¸€å®šè¦æŒ‡å®š `download_dir` å‚æ•°ï¼Œå¹¶ä¸”è¯¥ç›®å½•è·¯å¾„**å¿…é¡»ä»¥** `Qwen2.5-VL-3B-Instruct` **ç»“å°¾**ï¼ˆæ­£å¦‚é»˜è®¤å‚æ•°æ‰€ç¤ºï¼‰ï¼Œå¦åˆ™ä¸‹è½½å®ŒæˆååŒæ ·ä¼šå¯¼è‡´æ¡†æ¶æ— æ³•è¯†åˆ«æ¨¡å‹ã€‚

### ç¬¬äº”æ­¥ï¼šä¸€é”®è¿è¡Œ

```bash
cd gpu_pipelines
python image_region_caption_pipeline.py
```
> **ğŸ› ï¸ å¸¸è§é—®é¢˜æ’æŸ¥ (Troubleshooting)**
> 
> **é—®é¢˜ 1ï¼š** å¦‚æœé‡åˆ°ç±»ä¼¼å¦‚ä¸‹çš„åŠ¨æ€é“¾æ¥åº“å†²çªæŠ¥é”™ï¼š
> `ImportError: .../miniconda3/envs/Dataflow-MM/lib/python3.12/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkComplete_12_4, version libnvJitLink.so.12`
> 
> **è§£å†³æ–¹æ³•ï¼š** è¿™é€šå¸¸æ˜¯ç¯å¢ƒå˜é‡å¹²æ‰°å¯¼è‡´çš„ã€‚è¯·åœ¨è¿è¡Œå‘½ä»¤å‰æ¸…ç©º `LD_LIBRARY_PATH`ï¼š
> ```bash
> LD_LIBRARY_PATH="" python image_region_caption_pipeline.py
> ```
> 
> **é—®é¢˜ 2ï¼š** å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ **Qwen ç³»åˆ—æ¨¡å‹**ï¼Œå¹¶ä¸”é‡åˆ°ä»¥ä¸‹æŠ¥é”™ï¼š
> `KeyError: "Missing required keys in rope_scaling for 'rope_type'='None': {'rope_type'}"`
> 
> **è§£å†³æ–¹æ³•ï¼š** æ‰“å¼€æ¨¡å‹æ–‡ä»¶å¤¹ä¸‹çš„ `config.json` æ–‡ä»¶ï¼Œæ‰¾åˆ° `rope_scaling` é…ç½®å—ï¼Œå°† `"type"` å­—æ®µä¿®æ”¹ä¸º `"rope_type"` å³å¯ã€‚
> 
> **ä¿®æ”¹å‰ï¼š**
> ```json
> "rope_scaling": {
>   "type": "mrope",
>   "mrope_section": [
>     16,
>     24,
>     24
>   ]
> }
> ```
> 
> **ä¿®æ”¹åï¼š**
> ```json
> "rope_scaling": {
>   "rope_type": "mrope",
>   "mrope_section": [
>     16,
>     24,
>     24
>   ]
> }
> ```

---

## 3. æ•°æ®æµä¸æµæ°´çº¿é€»è¾‘

### 1. **è¾“å…¥æ•°æ®**

è¾“å…¥æ•°æ®é€šå¸¸åŒ…å«å›¾åƒè·¯å¾„å’Œå¯¹åº”çš„è¾¹ç•Œæ¡†åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼š

* **image**ï¼šå›¾åƒæ–‡ä»¶è·¯å¾„ã€‚
* **bbox**ï¼šè¾¹ç•Œæ¡†åæ ‡åˆ—è¡¨ï¼Œé€šå¸¸æ ¼å¼ä¸º `[[x, y, w, h], ...]`ã€‚

**è¾“å…¥æ•°æ®ç¤ºä¾‹**ï¼š

```json
{
    "image": "../example_data/image_region_caption/20.jpg",
    "bbox": [[196, 104, 310, 495], [50, 60, 100, 200]]
}

```

### 2. **æ ¸å¿ƒç®—å­é€»è¾‘**

è¯¥æµæ°´çº¿é€šè¿‡ä¸²è”ä¸¤ä¸ªæ ¸å¿ƒç®—å­æ¥å®Œæˆä»»åŠ¡ï¼š

#### A. **ImageBboxGeneratorï¼ˆè¾¹ç•Œæ¡†å¤„ç†å™¨ï¼‰**

è¯¥ç®—å­è´Ÿè´£å¤„ç†è§†è§‰å±‚é¢çš„ä»»åŠ¡ã€‚

* **è¾“å…¥**ï¼šåŸå§‹å›¾åƒ + `bbox` æ•°æ®ã€‚
* **åŠŸèƒ½**ï¼šè¯»å–è¾¹ç•Œæ¡†ï¼Œå°†å…¶ç»˜åˆ¶åœ¨å›¾åƒä¸Šï¼ˆå¯è§†åŒ–ï¼‰ï¼Œæˆ–è€…æ ¹æ®é…ç½®è¿›è¡Œé¢„å¤„ç†ã€‚
* **é…ç½® (`ExistingBBoxDataGenConfig`)**ï¼šæ§åˆ¶æœ€å¤§æ¡†æ•°é‡ (`max_boxes`)å’Œè¾“å…¥è¾“å‡ºè·¯å¾„ã€‚
* **è¾“å‡º**ï¼šå¸¦æœ‰è§†è§‰æ ‡è®°çš„æ–°å›¾åƒçš„jsonæ–‡ä»¶è¾“å‡ºè·¯å¾„ã€‚

#### B. **PromptedVQAGeneratorï¼ˆVQA ç”Ÿæˆå™¨ï¼‰**

è¯¥ç®—å­è´Ÿè´£åˆ©ç”¨ VLM ç”Ÿæˆæ–‡æœ¬ã€‚

* **è¾“å…¥**ï¼šä¸Šä¸€æ­¥çš„è¾“å‡ºã€‚
* **åŠŸèƒ½**ï¼šVLM æ¥æ”¶å¸¦æœ‰æ ‡è®°çš„å›¾åƒï¼Œæ ¹æ®æç¤ºç”Ÿæˆå¯¹åº”åŒºåŸŸçš„æè¿°ã€‚
* **è¾“å‡º**ï¼šåŒºåŸŸæè¿°æ–‡æœ¬ã€‚

### 3. **è¾“å‡ºæ•°æ®**

æœ€ç»ˆç”Ÿæˆçš„è¾“å‡ºæ•°æ®å°†åŒ…å«å¤„ç†åçš„å›¾åƒè·¯å¾„å’Œç”Ÿæˆçš„æè¿°ï¼š
* **image**ï¼šè¾“å…¥çš„å›¾ç‰‡è·¯å¾„ã€‚
* **type**ï¼šæ˜¯å¦ç»™å®šè¾¹ç•Œæ¡†ã€‚
* **bbox**ï¼šè¾¹ç•Œæ¡†å‚æ•°ã€‚
* **normalized_bbox**ï¼šæ ‡å‡†åŒ–åçš„è¾¹ç•Œæ¡†å‚æ•°ã€‚
* **result_file**ï¼šç»“æœè¾“å‡ºè·¯å¾„ã€‚
* **image_with_bbox**ï¼šç”»äº†æ¡†çš„å›¾åƒè·¯å¾„ã€‚
* **valid_bboxes_num**ï¼šæœ‰æ•ˆè¾¹ç•Œæ¡†æ•°é‡ã€‚
* **prompt**ï¼šVLMæ¥æ”¶çš„æç¤ºè¯ã€‚
* **answer**ï¼šç”Ÿæˆçš„åŒºåŸŸæè¿°åˆ—è¡¨ã€‚

**è¾“å‡ºæ•°æ®ç¤ºä¾‹**ï¼š

```json
{
    "image":"..\/example_data\/image_region_caption\/20.png",
    "type":"with_bbox",
    "bbox":[[196,104,310,495]],
    "normalized_bbox":[[0.128,0.125,0.329,0.72],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0]],
    "result_file":"..\/cache\/image_region_caption",
    "image_with_bbox":"..\/cache\/image_region_caption\\2_bbox_vis.jpg",
    "valid_bboxes_num":1,
    "prompt":"Describe the content of each marked region in the image. There are 1 regions: <region1> to <region1>.",
    "answer":"In <region1>, the focus is on the lower half of a person wearing high-heeled shoes with an ornate design. The setting appears to be a kitchen, with items such as a table with floral tablecloth, a broom, and various kitchen utensils visible in the background. The legs of another person can also be seen, indicating there may be interaction happening in this domestic space. The overall scene captures a domestic and casual atmosphere."
}

```

---

## 4. æµæ°´çº¿ç¤ºä¾‹

ä»¥ä¸‹æ˜¯å®Œæ•´çš„ `ImageRegionCaptionPipeline` ä»£ç å®ç°ã€‚

```python
from dataflow.serving.local_model_vlm_serving import LocalModelVLMServing_vllm
from dataflow.operators.core_vision.generate.image_bbox_generator import (
    ImageBboxGenerator, 
    ExistingBBoxDataGenConfig
)
from dataflow.operators.core_vision.generate.prompted_vqa_generator import (
    PromptedVQAGenerator
)
from dataflow.utils.storage import FileStorage


class ImageRegionCaptionPipeline:
    def __init__(
        self,
        model_path: str = "Qwen/Qwen2.5-VL-3B-Instruct",
        hf_cache_dir: str = "~/.cache/huggingface",
        download_dir: str = "../ckpt/models/Qwen2.5-VL-3B-Instruct",
        first_entry_file: str = "../example_data/image_region_caption/image_region_caption_demo.jsonl",
        cache_path: str = "../cache/image_region_caption",
        file_name_prefix: str = "region_caption",
        cache_type: str = "jsonl",
        input_image_key: str = "image",
        input_bbox_key: str = "bbox",
        max_boxes: int = 10,
        output_image_with_bbox_path: str = "../cache/image_region_caption/image_with_bbox_result.jsonl",
    ):
        self.bbox_storage = FileStorage(
            first_entry_file_name=first_entry_file,
            cache_path=cache_path,
            file_name_prefix=file_name_prefix,
            cache_type=cache_type
        )

        self.cfg = ExistingBBoxDataGenConfig(
            max_boxes=max_boxes,
            input_jsonl_path=first_entry_file,
            output_jsonl_path=output_image_with_bbox_path,
        )

        self.caption_storage = FileStorage(
            first_entry_file_name=output_image_with_bbox_path,
            cache_path=cache_path,
            file_name_prefix=file_name_prefix,
            cache_type=cache_type
        )
        self.serving = LocalModelVLMServing_vllm(
            hf_model_name_or_path=model_path,
            hf_cache_dir=hf_cache_dir,
            hf_local_dir=download_dir,
            vllm_tensor_parallel_size=1,
            vllm_temperature=0.7,
            vllm_top_p=0.9,
            vllm_max_tokens=512,
        )
        self.bbox_generator = ImageBboxGenerator(config=self.cfg)
        self.caption_generator = PromptedVQAGenerator(serving=self.serving,)
        self.input_image_key = input_image_key
        self.input_bbox_key = input_bbox_key
        self.bbox_record=None

    def forward(self):
        self.bbox_generator.run(
            storage=self.bbox_storage.step(),
            input_image_key=self.input_image_key,
            input_bbox_key=self.input_bbox_key,
        )

        self.caption_generator.run(
            storage=self.caption_storage.step(),
            input_image_key='image_with_bbox',
            input_prompt_key='prompt'
        )


if __name__ == "__main__":
    pipe = ImageRegionCaptionPipeline()
    pipe.forward()

```

